#!/usr/bin/env python3
"""
AI-CodeReview-GitLab é¡¹ç›®æ–‡ä»¶æ¸…ç†å’Œç»“æ„ä¼˜åŒ–è„šæœ¬
æ¸…ç†å†—ä½™æ–‡ä»¶ï¼Œä¼˜åŒ–é¡¹ç›®ç»“æ„ï¼Œæå‡å¯ç»´æŠ¤æ€§
"""

import os
import shutil
from pathlib import Path
import json

class ProjectCleaner:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.deleted_files = []
        self.moved_files = []
        self.merged_files = []
        self.errors = []
    
    def analyze_project_structure(self):
        """åˆ†æé¡¹ç›®ç»“æ„ï¼Œè¯†åˆ«éœ€è¦æ¸…ç†çš„æ–‡ä»¶"""
        print("ğŸ” åˆ†æé¡¹ç›®ç»“æ„...")
        
        # è¯†åˆ«é‡å¤å’Œå†—ä½™æ–‡ä»¶
        duplicates = self.find_duplicates()
        redundant_reports = self.find_redundant_reports()
        
        print(f"ğŸ“Š å‘ç° {len(duplicates)} ä¸ªé‡å¤æ–‡ä»¶")
        print(f"ğŸ“Š å‘ç° {len(redundant_reports)} ä¸ªå†—ä½™æŠ¥å‘Šæ–‡ä»¶")
        
        return duplicates, redundant_reports
    
    def find_duplicates(self):
        """æŸ¥æ‰¾é‡å¤æ–‡ä»¶"""
        duplicates = []
        
        # æ£€æŸ¥é‡å¤çš„æ–‡æ¡£ç›®å½•
        docs_dir = self.project_root / "docs"
        doc_dir = self.project_root / "doc"
        
        if docs_dir.exists() and doc_dir.exists():
            # æ£€æŸ¥ç›¸åŒåç§°çš„æ–‡ä»¶
            for docs_file in docs_dir.glob("*.md"):
                doc_file = doc_dir / docs_file.name
                if doc_file.exists():
                    duplicates.append({
                        'primary': docs_file,
                        'duplicate': doc_file,
                        'type': 'documentation'
                    })
        
        return duplicates
    
    def find_redundant_reports(self):
        """æŸ¥æ‰¾å†—ä½™çš„æŠ¥å‘Šæ–‡ä»¶"""
        redundant_reports = []
        
        # æŸ¥æ‰¾æ ¹ç›®å½•ä¸‹çš„çŠ¶æ€æŠ¥å‘Šæ–‡ä»¶
        report_patterns = [
            "*_REPORT.md",
            "*_SUMMARY.md", 
            "*_COMPLETE.md",
            "*_STATUS.md",
            "*_GUIDE.md"
        ]
        
        for pattern in report_patterns:
            for file in self.project_root.glob(pattern):
                # æ’é™¤é‡è¦çš„æ–‡ä»¶
                if file.name not in ['README.md', 'PROJECT_STATUS.md']:
                    redundant_reports.append(file)
        
        return redundant_reports
    
    def clean_duplicate_documentation(self):
        """æ¸…ç†é‡å¤çš„æ–‡æ¡£æ–‡ä»¶"""
        print("\nğŸ“š æ¸…ç†é‡å¤æ–‡æ¡£...")
        
        docs_dir = self.project_root / "docs"
        doc_dir = self.project_root / "doc"
        
        if not docs_dir.exists() or not doc_dir.exists():
            print("âœ… æœªå‘ç°é‡å¤æ–‡æ¡£ç›®å½•")
            return
        
        # åˆå¹¶ doc/ åˆ° docs/
        for doc_file in doc_dir.rglob("*"):
            if doc_file.is_file():
                relative_path = doc_file.relative_to(doc_dir)
                target_path = docs_dir / relative_path
                
                # åˆ›å»ºç›®æ ‡ç›®å½•
                target_path.parent.mkdir(parents=True, exist_ok=True)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if target_path.exists():
                    # æ¯”è¾ƒæ–‡ä»¶å†…å®¹ï¼Œä¿ç•™æ›´å®Œæ•´çš„ç‰ˆæœ¬
                    if self.compare_and_merge_files(doc_file, target_path):
                        print(f"ğŸ“ åˆå¹¶æ–‡æ¡£: {relative_path}")
                        self.merged_files.append(str(relative_path))
                else:
                    # ç›´æ¥ç§»åŠ¨
                    shutil.move(str(doc_file), str(target_path))
                    print(f"ğŸ“¦ ç§»åŠ¨æ–‡æ¡£: {relative_path}")
                    self.moved_files.append(f"{doc_file} -> {target_path}")
        
        # åˆ é™¤ç©ºçš„ doc/ ç›®å½•
        if doc_dir.exists() and not any(doc_dir.iterdir()):
            shutil.rmtree(doc_dir)
            print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: doc/")
            self.deleted_files.append("doc/")
    
    def compare_and_merge_files(self, file1, file2):
        """æ¯”è¾ƒå¹¶åˆå¹¶ä¸¤ä¸ªæ–‡ä»¶ï¼Œä¿ç•™æ›´å®Œæ•´çš„ç‰ˆæœ¬"""
        try:
            with open(file1, 'r', encoding='utf-8') as f1:
                content1 = f1.read()
            with open(file2, 'r', encoding='utf-8') as f2:
                content2 = f2.read()
            
            # å¦‚æœå†…å®¹ç›¸åŒï¼Œæ— éœ€æ“ä½œ
            if content1 == content2:
                return False
            
            # å¦‚æœå…¶ä¸­ä¸€ä¸ªæ–‡ä»¶æ›´é•¿ï¼Œä¿ç•™æ›´é•¿çš„
            if len(content1) > len(content2):
                shutil.copy2(file1, file2)
                return True
            elif len(content2) > len(content1):
                return False
            
            # é•¿åº¦ç›¸åŒï¼Œä¿ç•™ä¿®æ”¹æ—¶é—´æ›´æ–°çš„
            if file1.stat().st_mtime > file2.stat().st_mtime:
                shutil.copy2(file1, file2)
                return True
            
            return False
        except Exception as e:
            self.errors.append(f"æ¯”è¾ƒæ–‡ä»¶å¤±è´¥: {file1} vs {file2} - {e}")
            return False
    
    def clean_redundant_reports(self):
        """æ¸…ç†å†—ä½™çš„æŠ¥å‘Šæ–‡ä»¶"""
        print("\nğŸ“‹ æ¸…ç†å†—ä½™æŠ¥å‘Šæ–‡ä»¶...")
        
        # è¦ä¿ç•™çš„é‡è¦æ–‡ä»¶
        keep_files = {
            'README.md',
            'PROJECT_STATUS.md',
            'CHANGELOG.md',
            'LICENSE'
        }
        
        # è¦æ¸…ç†çš„æŠ¥å‘Šæ–‡ä»¶æ¨¡å¼
        cleanup_patterns = [
            "*_REPORT.md",
            "*_SUMMARY.md",
            "*_COMPLETE.md",
            "*_GUIDE.md",
            "PYTHON_UPGRADE*.md",
            "YAML_SYNTAX_FIX.md",
            "FIX_*.md",
            "CONFIG_*.md"
        ]
        
        cleaned_count = 0
        for pattern in cleanup_patterns:
            for file in self.project_root.glob(pattern):
                if file.name not in keep_files:
                    try:
                        file.unlink()
                        print(f"ğŸ—‘ï¸ åˆ é™¤æŠ¥å‘Šæ–‡ä»¶: {file.name}")
                        self.deleted_files.append(file.name)
                        cleaned_count += 1
                    except Exception as e:
                        self.errors.append(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file.name} - {e}")
        
        print(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªå†—ä½™æŠ¥å‘Šæ–‡ä»¶")
    
    def clean_docker_compose_files(self):
        """æ¸…ç†å¤šä½™çš„ Docker Compose æ–‡ä»¶"""
        print("\nğŸ³ æ¸…ç† Docker Compose æ–‡ä»¶...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ª docker-compose æ–‡ä»¶
        compose_files = list(self.project_root.glob("docker-compose*.yml"))
        
        if len(compose_files) <= 2:
            print("âœ… Docker Compose æ–‡ä»¶æ•°é‡åˆç†")
            return
        
        # ä¿ç•™ä¸»è¦çš„ä¸¤ä¸ªæ–‡ä»¶
        keep_files = {
            'docker-compose.yml',
            'docker-compose.dockerhub.yml'
        }
        
        for compose_file in compose_files:
            if compose_file.name not in keep_files:
                try:
                    compose_file.unlink()
                    print(f"ğŸ—‘ï¸ åˆ é™¤å¤šä½™çš„ Compose æ–‡ä»¶: {compose_file.name}")
                    self.deleted_files.append(compose_file.name)
                except Exception as e:
                    self.errors.append(f"åˆ é™¤ Compose æ–‡ä»¶å¤±è´¥: {compose_file.name} - {e}")
    
    def optimize_scripts_directory(self):
        """ä¼˜åŒ– scripts ç›®å½•ç»“æ„"""
        print("\nğŸ”§ ä¼˜åŒ– scripts ç›®å½•...")
        
        scripts_dir = self.project_root / "scripts"
        if not scripts_dir.exists():
            return
        
        # æ£€æŸ¥è„šæœ¬åŠŸèƒ½é‡å¤
        verify_scripts = list(scripts_dir.glob("verify_build_config*.py"))
        
        if len(verify_scripts) > 1:
            # ä¿ç•™åŠŸèƒ½æ›´å®Œæ•´çš„ç‰ˆæœ¬
            main_script = None
            for script in verify_scripts:
                if "simple" not in script.name:
                    main_script = script
                    break
            
            if main_script:
                for script in verify_scripts:
                    if script != main_script:
                        try:
                            script.unlink()
                            print(f"ğŸ—‘ï¸ åˆ é™¤é‡å¤éªŒè¯è„šæœ¬: {script.name}")
                            self.deleted_files.append(script.name)
                        except Exception as e:
                            self.errors.append(f"åˆ é™¤è„šæœ¬å¤±è´¥: {script.name} - {e}")
    
    def clean_empty_directories(self):
        """æ¸…ç†ç©ºç›®å½•"""
        print("\nğŸ“ æ¸…ç†ç©ºç›®å½•...")
        
        empty_dirs = []
        for root, dirs, files in os.walk(self.project_root):
            if not dirs and not files:
                empty_dirs.append(Path(root))
        
        for empty_dir in empty_dirs:
            try:
                empty_dir.rmdir()
                print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {empty_dir.relative_to(self.project_root)}")
                self.deleted_files.append(str(empty_dir.relative_to(self.project_root)))
            except Exception as e:
                self.errors.append(f"åˆ é™¤ç©ºç›®å½•å¤±è´¥: {empty_dir} - {e}")
    
    def create_cleanup_summary(self):
        """åˆ›å»ºæ¸…ç†æ€»ç»“æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæ¸…ç†æ€»ç»“...")
        
        summary = {
            "cleanup_date": "2025-06-23",
            "deleted_files": self.deleted_files,
            "moved_files": self.moved_files,
            "merged_files": self.merged_files,
            "errors": self.errors,
            "statistics": {
                "deleted_count": len(self.deleted_files),
                "moved_count": len(self.moved_files), 
                "merged_count": len(self.merged_files),
                "error_count": len(self.errors)
            }
        }
        
        # åˆ›å»ºæ¸…ç†æŠ¥å‘Š
        report_content = f"""# ğŸ§¹ é¡¹ç›®æ–‡ä»¶æ¸…ç†æŠ¥å‘Š

## ğŸ“… æ¸…ç†æ—¶é—´
**æ‰§è¡Œæ—¥æœŸ:** 2025-06-23  
**æ¸…ç†çŠ¶æ€:** {'âœ… å®Œæˆ' if not self.errors else 'âš ï¸ éƒ¨åˆ†å®Œæˆ'}  

## ğŸ“Š æ¸…ç†ç»Ÿè®¡

- **åˆ é™¤æ–‡ä»¶:** {len(self.deleted_files)} ä¸ª
- **ç§»åŠ¨æ–‡ä»¶:** {len(self.moved_files)} ä¸ª  
- **åˆå¹¶æ–‡ä»¶:** {len(self.merged_files)} ä¸ª
- **é”™è¯¯æ•°é‡:** {len(self.errors)} ä¸ª

## ğŸ—‘ï¸ å·²åˆ é™¤çš„æ–‡ä»¶

{chr(10).join([f"- {f}" for f in self.deleted_files]) if self.deleted_files else "æ— åˆ é™¤æ–‡ä»¶"}

## ğŸ“¦ å·²ç§»åŠ¨çš„æ–‡ä»¶

{chr(10).join([f"- {f}" for f in self.moved_files]) if self.moved_files else "æ— ç§»åŠ¨æ–‡ä»¶"}

## ğŸ“ å·²åˆå¹¶çš„æ–‡ä»¶

{chr(10).join([f"- {f}" for f in self.merged_files]) if self.merged_files else "æ— åˆå¹¶æ–‡ä»¶"}

{'## âŒ å¤„ç†é”™è¯¯' + chr(10) + chr(10).join([f"- {e}" for e in self.errors]) if self.errors else ''}

## ğŸ¯ ä¼˜åŒ–æ•ˆæœ

### é¡¹ç›®ç»“æ„æ›´æ¸…æ™°
- ç§»é™¤å†—ä½™çš„çŠ¶æ€æŠ¥å‘Šæ–‡ä»¶
- åˆå¹¶é‡å¤çš„æ–‡æ¡£ç›®å½•
- æ¸…ç†å¤šä½™çš„é…ç½®æ–‡ä»¶

### ç»´æŠ¤æ€§æå‡
- å‡å°‘æ–‡ä»¶å†—ä½™
- ç»Ÿä¸€æ–‡æ¡£ç»“æ„
- ç®€åŒ–é¡¹ç›®å¯¼èˆª

## ğŸ“ ä¼˜åŒ–åçš„é¡¹ç›®ç»“æ„

```
AI-Codereview-Gitlab/
â”œâ”€â”€ ğŸ“‚ æ ¸å¿ƒæ–‡ä»¶
â”‚   â”œâ”€â”€ api.py              # Flask API æœåŠ¡
â”‚   â”œâ”€â”€ ui.py               # Streamlit Web ç•Œé¢
â”‚   â”œâ”€â”€ quick_start.py      # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ requirements.txt    # ä¾èµ–é…ç½®
â”‚
â”œâ”€â”€ ğŸ“‚ Docker é…ç½®
â”‚   â”œâ”€â”€ Dockerfile                    # å®¹å™¨æ„å»º
â”‚   â”œâ”€â”€ docker-compose.yml           # é»˜è®¤éƒ¨ç½²
â”‚   â””â”€â”€ docker-compose.dockerhub.yml # Docker Hub éƒ¨ç½²
â”‚
â”œâ”€â”€ ğŸ“‚ ä¸šåŠ¡é€»è¾‘
â”‚   â””â”€â”€ biz/                # æ ¸å¿ƒä¸šåŠ¡æ¨¡å—
â”‚
â”œâ”€â”€ ğŸ“‚ é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ conf/               # åº”ç”¨é…ç½®
â”‚
â”œâ”€â”€ ğŸ“‚ è„šæœ¬å·¥å…·
â”‚   â””â”€â”€ scripts/            # ç®¡ç†å’Œéƒ¨ç½²è„šæœ¬
â”‚
â”œâ”€â”€ ğŸ“‚ æµ‹è¯•æ–‡ä»¶
â”‚   â””â”€â”€ tests/              # æµ‹è¯•ä»£ç 
â”‚
â”œâ”€â”€ ğŸ“‚ æ–‡æ¡£èµ„æ–™
â”‚   â””â”€â”€ docs/               # ç»Ÿä¸€çš„æ–‡æ¡£ç›®å½•
â”‚
â”œâ”€â”€ ğŸ“‚ æ•°æ®å’Œæ—¥å¿—
â”‚   â”œâ”€â”€ data/               # æ•°æ®å­˜å‚¨
â”‚   â””â”€â”€ log/                # æ—¥å¿—æ–‡ä»¶
â”‚
â””â”€â”€ ğŸ“„ é¡¹ç›®è¯´æ˜
    â”œâ”€â”€ README.md           # é¡¹ç›®ä¸»æ–‡æ¡£
    â”œâ”€â”€ PROJECT_STATUS.md   # é¡¹ç›®çŠ¶æ€
    â””â”€â”€ CHANGELOG.md        # æ›´æ–°è®°å½•
```

---

*ğŸ‰ é¡¹ç›®æ¸…ç†å®Œæˆï¼ç»“æ„æ›´æ¸…æ™°ï¼Œç»´æŠ¤æ›´å®¹æ˜“ã€‚*
"""
        
        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        report_file = self.project_root / "PROJECT_CLEANUP_FINAL.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return summary
    
    def run_cleanup(self):
        """æ‰§è¡Œå®Œæ•´çš„æ¸…ç†æµç¨‹"""
        print("ğŸ§¹ å¼€å§‹ AI-CodeReview-GitLab é¡¹ç›®æ–‡ä»¶æ¸…ç†")
        print("=" * 60)
        
        try:
            # åˆ†æé¡¹ç›®ç»“æ„
            self.analyze_project_structure()
            
            # æ‰§è¡Œæ¸…ç†æ“ä½œ
            self.clean_duplicate_documentation()
            self.clean_redundant_reports() 
            self.clean_docker_compose_files()
            self.optimize_scripts_directory()
            self.clean_empty_directories()
            
            # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
            summary = self.create_cleanup_summary()
            
            print("\n" + "=" * 60)
            print("ğŸ‰ é¡¹ç›®æ¸…ç†å®Œæˆ!")
            print(f"ğŸ“Š åˆ é™¤æ–‡ä»¶: {len(self.deleted_files)} ä¸ª")
            print(f"ğŸ“¦ ç§»åŠ¨æ–‡ä»¶: {len(self.moved_files)} ä¸ª")
            print(f"ğŸ“ åˆå¹¶æ–‡ä»¶: {len(self.merged_files)} ä¸ª")
            
            if self.errors:
                print(f"âš ï¸ é‡åˆ°é”™è¯¯: {len(self.errors)} ä¸ª")
                for error in self.errors:
                    print(f"   â€¢ {error}")
            else:
                print("âœ… æ¸…ç†è¿‡ç¨‹æ— é”™è¯¯")
            
            print("\nğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: PROJECT_CLEANUP_FINAL.md")
            
            return True
            
        except Exception as e:
            print(f"\nğŸ’¥ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    cleaner = ProjectCleaner()
    success = cleaner.run_cleanup()
    return 0 if success else 1

if __name__ == "__main__":
    import sys
    sys.exit(main())
