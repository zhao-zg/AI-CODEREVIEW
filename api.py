from dotenv import load_dotenv

load_dotenv("conf/.env")

import atexit
import json
import os
import signal
import traceback
import threading
import time
from datetime import datetime
from urllib.parse import urlparse

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from flask import Flask, request, jsonify, Response

from biz.gitlab.webhook_handler import slugify_url
from biz.queue.worker import handle_merge_request_event, handle_push_event, handle_github_pull_request_event, \
    handle_github_push_event
from biz.svn.svn_worker import handle_svn_changes, handle_multiple_svn_repositories
from biz.service.review_service import ReviewService
from biz.utils.im import notifier
from biz.utils.log import logger
from biz.utils.queue import handle_queue
from biz.utils.reporter import Reporter

from biz.utils.config_checker import check_config
from biz.utils.default_config import get_env_bool, get_env_with_default, get_env_int

api_app = Flask(__name__)

# é…ç½® Flask åº”ç”¨ä»¥æ”¯æŒä¸­æ–‡è¾“å‡º
api_app.config['JSON_AS_ASCII'] = False  # ç¡®ä¿ JSON å“åº”æ”¯æŒä¸­æ–‡
api_app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True  # ç¾åŒ– JSON è¾“å‡º

# å…¨å±€é…ç½®å˜é‡
push_review_enabled = get_env_bool('PUSH_REVIEW_ENABLED')
svn_check_enabled = get_env_bool('SVN_CHECK_ENABLED')

# åå°ä»»åŠ¡ç›¸å…³å…¨å±€å˜é‡
background_threads = []
scheduler = None


def reload_config():
    """é‡æ–°åŠ è½½é…ç½®å¹¶é‡æ–°é…ç½®å®šæ—¶ä»»åŠ¡"""
    global push_review_enabled, svn_check_enabled, scheduler
    
    try:
        logger.info("ğŸ”„ å¼€å§‹é‡æ–°åŠ è½½é…ç½®...")
        
        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv("conf/.env", override=True)
        
        # æ›´æ–°å…¨å±€é…ç½®å˜é‡
        push_review_enabled = get_env_bool('PUSH_REVIEW_ENABLED')
        svn_check_enabled = get_env_bool('SVN_CHECK_ENABLED')
        
        # ğŸ”„ é‡æ–°é…ç½®å®šæ—¶ä»»åŠ¡ï¼ˆå¦‚æœè°ƒåº¦å™¨å·²å¯åŠ¨ï¼‰
        if scheduler and scheduler.running:
            logger.info("ğŸ”„ æ£€æµ‹åˆ°è°ƒåº¦å™¨æ­£åœ¨è¿è¡Œï¼Œæ­£åœ¨é‡æ–°é…ç½®å®šæ—¶ä»»åŠ¡...")
            
            # ç§»é™¤æ‰€æœ‰ç°æœ‰ä»»åŠ¡
            old_jobs = scheduler.get_jobs()
            scheduler.remove_all_jobs()
            logger.info(f"å·²ç§»é™¤ {len(old_jobs)} ä¸ªæ—§çš„å®šæ—¶ä»»åŠ¡")
            
            # é‡æ–°æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼ˆä¸é‡æ–°åˆ›å»ºè°ƒåº¦å™¨ï¼‰
            reconfigure_scheduler_jobs()
            
            new_jobs = scheduler.get_jobs()
            logger.info(f"âœ… å·²é‡æ–°é…ç½® {len(new_jobs)} ä¸ªå®šæ—¶ä»»åŠ¡")
        else:
            logger.info("â„¹ï¸ è°ƒåº¦å™¨æœªè¿è¡Œï¼Œè·³è¿‡å®šæ—¶ä»»åŠ¡é‡æ–°é…ç½®")
        
        logger.info("âœ… APIæœåŠ¡é…ç½®å·²é‡æ–°åŠ è½½")
        print("[API] é…ç½®å·²é‡æ–°åŠ è½½ï¼ˆåŒ…æ‹¬å®šæ—¶ä»»åŠ¡ï¼‰")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ APIæœåŠ¡é‡æ–°åŠ è½½é…ç½®å¤±è´¥: {e}")
        print(f"[API] é‡æ–°åŠ è½½é…ç½®å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def setup_signal_handlers():
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
    def signal_handler(signum, frame):
        if hasattr(signal, 'SIGUSR1') and signum == signal.SIGUSR1:
            print("[API] æ”¶åˆ°é…ç½®é‡è½½ä¿¡å· (SIGUSR1)")
            reload_config()
        elif signum == signal.SIGTERM:
            print("[API] æ”¶åˆ°ç»ˆæ­¢ä¿¡å· (SIGTERM)")
            # è¿™é‡Œå¯ä»¥æ·»åŠ ä¼˜é›…å…³é—­é€»è¾‘
            shutdown_background_tasks()
        elif hasattr(signal, 'SIGHUP') and signum == signal.SIGHUP:
            print("[API] æ”¶åˆ°é‡å¯ä¿¡å· (SIGHUP)")
            reload_config()
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆä»…åœ¨æ”¯æŒçš„ç³»ç»Ÿä¸Šï¼‰
    if hasattr(signal, 'SIGUSR1'):
        signal.signal(signal.SIGUSR1, signal_handler)  # é…ç½®é‡è½½
    signal.signal(signal.SIGTERM, signal_handler)  # ä¼˜é›…å…³é—­
    if hasattr(signal, 'SIGHUP'):
        signal.signal(signal.SIGHUP, signal_handler)   # é‡å¯/é‡è½½


# è®¾ç½®ä¿¡å·å¤„ç†å™¨
setup_signal_handlers()

@api_app.route('/')
def home():
    svn_status = "å·²å¯ç”¨" if svn_check_enabled else "æœªå¯ç”¨"
    
    # è·å–SVNä»“åº“ä¿¡æ¯
    svn_info = ""
    if svn_check_enabled:
        import json
        svn_repositories_config = get_env_with_default('SVN_REPOSITORIES')
        try:
            repositories = json.loads(svn_repositories_config)
            if repositories:
                svn_info = f"<p><strong>é…ç½®çš„SVNä»“åº“:</strong></p><ul>"
                for repo in repositories:
                    name = repo.get('name', 'unknown')
                    url = repo.get('remote_url', 'unknown')
                    svn_info += f"<li>{name}: {url}</li>"
                svn_info += "</ul>"
            else:
                # æ£€æŸ¥å•ä»“åº“é…ç½®
                svn_remote_url = get_env_with_default('SVN_REMOTE_URL')
                if svn_remote_url:
                    svn_info = f"<p><strong>SVNä»“åº“:</strong> {svn_remote_url}</p>"
        except json.JSONDecodeError:
            svn_info = "<p><strong>SVNé…ç½®:</strong> é…ç½®è§£æé”™è¯¯</p>"
    
    return f"""<h2>AIä»£ç å®¡æŸ¥æœåŠ¡æ­£åœ¨è¿è¡Œ</h2>
              <p><strong>SVNå®šæ—¶æ£€æŸ¥åŠŸèƒ½ï¼š</strong> {svn_status}</p>
              {svn_info}              <p><strong>GitHubé¡¹ç›®åœ°å€:</strong> <a href="https://github.com/zhao-zg/AI-CODEREVIEW" target="_blank">
              https://github.com/zhao-zg/AI-CODEREVIEW</a></p>
              <p><strong>Dockeré•œåƒ:</strong> <a href="https://github.com/zhao-zg/AI-CODEREVIEW/pkgs/container/ai-codereview" target="_blank">
              ghcr.io/zhao-zg/ai-codereview</a></p>
              <p><strong>æ”¯æŒçš„åŠŸèƒ½:</strong></p>
              <ul>
                <li>GitLab Webhook è§¦å‘å®¡æŸ¥</li>
                <li>GitHub Webhook è§¦å‘å®¡æŸ¥</li>
                <li>SVN å®šæ—¶æ£€æŸ¥å®¡æŸ¥ï¼ˆæ”¯æŒå¤šä»“åº“ï¼‰</li>
                <li>æ‰‹åŠ¨è§¦å‘ SVN æ£€æŸ¥: <a href="/svn/check" target="_blank">POST /svn/check</a></li>
                <li>æ‰‹åŠ¨è§¦å‘æŒ‡å®šä»“åº“: <a href="/svn/check?repo=ä»“åº“å" target="_blank">POST /svn/check?repo=ä»“åº“å</a></li>
              </ul>
              """


@api_app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "healthy",
        "message": "AI Code Review service is running",
        "timestamp": datetime.now().isoformat()
    })


@api_app.route('/review/daily_report', methods=['GET'])
def daily_report():
    # è·å–å½“å‰æ—¥æœŸ0ç‚¹å’Œ23ç‚¹59åˆ†59ç§’çš„æ—¶é—´æˆ³
    start_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).timestamp()
    end_time = datetime.now().replace(hour=23, minute=59, second=59, microsecond=0).timestamp()

    try:
        if push_review_enabled:
            df = ReviewService().get_push_review_logs(updated_at_gte=start_time, updated_at_lte=end_time)
        else:
            df = ReviewService().get_mr_review_logs(updated_at_gte=start_time, updated_at_lte=end_time)

        if df.empty:
            logger.info("No data to process.")
            return jsonify({'message': 'No data to process.'}), 200
        # å»é‡ï¼šåŸºäº (author, message) ç»„åˆ
        df_unique = df.drop_duplicates(subset=["author", "commit_messages"])
        # æŒ‰ç…§ author æ’åº
        df_sorted = df_unique.sort_values(by="author")
        # è½¬æ¢ä¸ºé€‚åˆç”Ÿæˆæ—¥æŠ¥çš„æ ¼å¼
        commits = df_sorted.to_dict(orient="records")
        # ç”Ÿæˆæ—¥æŠ¥å†…å®¹
        report_txt = Reporter().generate_report(json.dumps(commits))
        # å‘é€é’‰é’‰é€šçŸ¥
        notifier.send_notification(content=report_txt, msg_type="markdown", title="ä»£ç æäº¤æ—¥æŠ¥")

        # è¿”å›ç”Ÿæˆçš„æ—¥æŠ¥å†…å®¹
        return json.dumps(report_txt, ensure_ascii=False, indent=4)
    except Exception as e:
        logger.error(f"Failed to generate daily report: {e}")
        return jsonify({'message': f"Failed to generate daily report: {e}"}), 500


def reconfigure_scheduler_jobs():
    """
    é‡æ–°é…ç½®è°ƒåº¦å™¨çš„ä»»åŠ¡ï¼ˆä¸é‡æ–°åˆ›å»ºè°ƒåº¦å™¨ï¼‰
    ç”¨äºé…ç½®çƒ­é‡è½½æ—¶é‡æ–°æ·»åŠ å®šæ—¶ä»»åŠ¡
    """
    global scheduler, svn_check_enabled
    
    if not scheduler:
        logger.error("è°ƒåº¦å™¨æœªåˆå§‹åŒ–")
        return
    
    try:
        # 1. æ·»åŠ æ—¥æŠ¥å®šæ—¶ä»»åŠ¡
        crontab_expression = get_env_with_default('REPORT_CRONTAB_EXPRESSION')
        logger.info(f"ğŸ“… é…ç½®æ—¥æŠ¥å®šæ—¶ä»»åŠ¡ï¼Œcronè¡¨è¾¾å¼: '{crontab_expression}'")
        cron_parts = crontab_expression.split()
        
        if len(cron_parts) == 6:
            # 6æ®µå¼ï¼šç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨
            cron_second, cron_minute, cron_hour, cron_day, cron_month, cron_day_of_week = cron_parts
            scheduler.add_job(
                daily_report,
                trigger=CronTrigger(
                    second=cron_second,
                    minute=cron_minute,
                    hour=cron_hour,
                    day=cron_day,
                    month=cron_month,
                    day_of_week=cron_day_of_week
                ),
                id="daily_report",
                name="æ¯æ—¥å·¥ä½œæ—¥æŠ¥"
            )
            logger.info(f"âœ… æ—¥æŠ¥å®šæ—¶ä»»åŠ¡å·²é…ç½®ï¼ˆå«ç§’ï¼‰: {crontab_expression}")
        elif len(cron_parts) == 5:
            # 5æ®µå¼ï¼šåˆ† æ—¶ æ—¥ æœˆ å‘¨
            cron_minute, cron_hour, cron_day, cron_month, cron_day_of_week = cron_parts
            scheduler.add_job(
                daily_report,
                trigger=CronTrigger(
                    minute=cron_minute,
                    hour=cron_hour,
                    day=cron_day,
                    month=cron_month,
                    day_of_week=cron_day_of_week
                ),
                id="daily_report",
                name="æ¯æ—¥å·¥ä½œæ—¥æŠ¥"
            )
            logger.info(f"âœ… æ—¥æŠ¥å®šæ—¶ä»»åŠ¡å·²é…ç½®: {crontab_expression}")
        else:
            logger.error(f"âŒ æ—¥æŠ¥cronè¡¨è¾¾å¼æ ¼å¼é”™è¯¯: '{crontab_expression}'ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            scheduler.add_job(
                daily_report,
                trigger=CronTrigger(minute=0, hour=18, day='*', month='*', day_of_week='mon-fri'),
                id="daily_report",
                name="æ¯æ—¥å·¥ä½œæ—¥æŠ¥"
            )
        
        # 2. æ·»åŠ SVNå®šæ—¶æ£€æŸ¥ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if svn_check_enabled:
            logger.info("ğŸ“… é…ç½®SVNå®šæ—¶æ£€æŸ¥ä»»åŠ¡...")
            
            # å°è¯•ä¸ºæ¯ä¸ªä»“åº“åˆ›å»ºç‹¬ç«‹ä»»åŠ¡
            svn_repositories_str = get_env_with_default('SVN_REPOSITORIES')
            individual_tasks_created = False
            
            if svn_repositories_str:
                try:
                    import json
                    repositories = json.loads(svn_repositories_str)
                    if isinstance(repositories, list):
                        for repo_config in repositories:
                            repo_name = repo_config.get('name', 'unknown')
                            repo_crontab = repo_config.get('check_crontab')
                            
                            if repo_crontab:
                                svn_cron_parts = repo_crontab.split()
                                
                                if len(svn_cron_parts) == 6:
                                    svn_second, svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                                    scheduler.add_job(
                                        lambda repo=repo_config: trigger_single_svn_repo_check(repo),
                                        trigger=CronTrigger(
                                            second=svn_second,
                                            minute=svn_minute,
                                            hour=svn_hour,
                                            day=svn_day,
                                            month=svn_month,
                                            day_of_week=svn_day_of_week
                                        ),
                                        id=f"svn_check_{repo_name}",
                                        name=f"SVNæ£€æŸ¥ - {repo_name}"
                                    )
                                    logger.info(f"âœ… ä»“åº“ {repo_name} å®šæ—¶ä»»åŠ¡å·²é…ç½®ï¼ˆå«ç§’ï¼‰: {repo_crontab}")
                                    individual_tasks_created = True
                                elif len(svn_cron_parts) == 5:
                                    svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                                    scheduler.add_job(
                                        lambda repo=repo_config: trigger_single_svn_repo_check(repo),
                                        trigger=CronTrigger(
                                            minute=svn_minute,
                                            hour=svn_hour,
                                            day=svn_day,
                                            month=svn_month,
                                            day_of_week=svn_day_of_week
                                        ),
                                        id=f"svn_check_{repo_name}",
                                        name=f"SVNæ£€æŸ¥ - {repo_name}"
                                    )
                                    logger.info(f"âœ… ä»“åº“ {repo_name} å®šæ—¶ä»»åŠ¡å·²é…ç½®: {repo_crontab}")
                                    individual_tasks_created = True
                except (json.JSONDecodeError, Exception) as e:
                    logger.error(f"è§£æ SVN_REPOSITORIES é…ç½®å¤±è´¥: {e}")
            
            # åˆ›å»ºå…¨å±€ä»»åŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not individual_tasks_created or svn_repositories_str:
                svn_crontab = get_env_with_default('SVN_CHECK_CRONTAB')
                svn_cron_parts = svn_crontab.split()
                
                if len(svn_cron_parts) == 6:
                    svn_second, svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                    scheduler.add_job(
                        trigger_svn_check,
                        trigger=CronTrigger(
                            second=svn_second,
                            minute=svn_minute,
                            hour=svn_hour,
                            day=svn_day,
                            month=svn_month,
                            day_of_week=svn_day_of_week
                        ),
                        id="svn_check_global",
                        name="SVNå…¨å±€æ£€æŸ¥"
                    )
                    logger.info(f"âœ… SVNå…¨å±€å®šæ—¶ä»»åŠ¡å·²é…ç½®ï¼ˆå«ç§’ï¼‰: {svn_crontab}")
                elif len(svn_cron_parts) == 5:
                    svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                    scheduler.add_job(
                        trigger_svn_check,
                        trigger=CronTrigger(
                            minute=svn_minute,
                            hour=svn_hour,
                            day=svn_day,
                            month=svn_month,
                            day_of_week=svn_day_of_week
                        ),
                        id="svn_check_global",
                        name="SVNå…¨å±€æ£€æŸ¥"
                    )
                    logger.info(f"âœ… SVNå…¨å±€å®šæ—¶ä»»åŠ¡å·²é…ç½®: {svn_crontab}")
        else:
            logger.info("â„¹ï¸ SVNæ£€æŸ¥å·²ç¦ç”¨ï¼Œè·³è¿‡SVNå®šæ—¶ä»»åŠ¡é…ç½®")
        
        logger.info("âœ… æ‰€æœ‰å®šæ—¶ä»»åŠ¡é‡æ–°é…ç½®å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ é‡æ–°é…ç½®å®šæ—¶ä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


def setup_scheduler():
    """
    é…ç½®å¹¶å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    """
    global scheduler
    
    try:
        scheduler = BackgroundScheduler()
          # æ—¥æŠ¥å®šæ—¶ä»»åŠ¡
        crontab_expression = get_env_with_default('REPORT_CRONTAB_EXPRESSION')
        logger.info(f"ğŸ“… Reading cron expression: '{crontab_expression}'")
        cron_parts = crontab_expression.split()
        logger.info(f"ğŸ“‹ Cron parts after split: {cron_parts} (count: {len(cron_parts)})")
        
        # éªŒè¯cronè¡¨è¾¾å¼æ ¼å¼ï¼ˆæ”¯æŒ5æ®µå¼å’Œ6æ®µå¼ï¼‰
        if len(cron_parts) == 6:
            # 6æ®µå¼ï¼šç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨
            cron_second, cron_minute, cron_hour, cron_day, cron_month, cron_day_of_week = cron_parts
            logger.info(f"âœ… Cron schedule set (with seconds): second={cron_second}, minute={cron_minute}, hour={cron_hour}, day={cron_day}, month={cron_month}, day_of_week={cron_day_of_week}")
            scheduler.add_job(
                daily_report,
                trigger=CronTrigger(
                    second=cron_second,
                    minute=cron_minute,
                    hour=cron_hour,
                    day=cron_day,
                    month=cron_month,
                    day_of_week=cron_day_of_week
                )
            )
        elif len(cron_parts) == 5:
            # 5æ®µå¼ï¼šåˆ† æ—¶ æ—¥ æœˆ å‘¨ï¼ˆå‘åå…¼å®¹ï¼‰
            cron_minute, cron_hour, cron_day, cron_month, cron_day_of_week = cron_parts
            logger.info(f"âœ… Cron schedule set: minute={cron_minute}, hour={cron_hour}, day={cron_day}, month={cron_month}, day_of_week={cron_day_of_week}")
            scheduler.add_job(
                daily_report,
                trigger=CronTrigger(
                    minute=cron_minute,
                    hour=cron_hour,
                    day=cron_day,
                    month=cron_month,
                    day_of_week=cron_day_of_week
                )
            )
        else:
            logger.error(f"âŒ Invalid cron expression format: '{crontab_expression}'. Expected 5 or 6 parts, got {len(cron_parts)}")
            logger.info(f"ğŸ’¡ Using default cron expression: '0 18 * * 1-5'")
            cron_parts = '0 18 * * 1-5'.split()
            cron_minute, cron_hour, cron_day, cron_month, cron_day_of_week = cron_parts
            scheduler.add_job(
                daily_report,
                trigger=CronTrigger(
                    minute=cron_minute,
                    hour=cron_hour,
                    day=cron_day,
                    month=cron_month,
                    day_of_week=cron_day_of_week
                )
            )
        
        # SVNå®šæ—¶æ£€æŸ¥ä»»åŠ¡
        if svn_check_enabled:
            # é¦–å…ˆå°è¯•ä» SVN_REPOSITORIES é…ç½®ä¸­ä¸ºæ¯ä¸ªä»“åº“åˆ›å»ºç‹¬ç«‹ä»»åŠ¡
            svn_repositories_str = get_env_with_default('SVN_REPOSITORIES')
            individual_tasks_created = False
            
            if svn_repositories_str:
                try:
                    import json
                    repositories = json.loads(svn_repositories_str)
                    if isinstance(repositories, list):
                        for repo_config in repositories:
                            repo_name = repo_config.get('name', 'unknown')
                            repo_crontab = repo_config.get('check_crontab')
                            
                            if repo_crontab:
                                svn_cron_parts = repo_crontab.split()
                                
                                if len(svn_cron_parts) == 6:
                                    # 6æ®µå¼ï¼šç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨
                                    svn_second, svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                                    scheduler.add_job(
                                        lambda repo=repo_config: trigger_single_svn_repo_check(repo),
                                        trigger=CronTrigger(
                                            second=svn_second,
                                            minute=svn_minute,
                                            hour=svn_hour,
                                            day=svn_day,
                                            month=svn_month,
                                            day_of_week=svn_day_of_week
                                        ),
                                        id=f"svn_check_{repo_name}",
                                        name=f"SVNæ£€æŸ¥ä»»åŠ¡ - {repo_name}"
                                    )
                                    logger.info(f"ä¸ºä»“åº“ {repo_name} åˆ›å»ºç‹¬ç«‹å®šæ—¶ä»»åŠ¡ï¼ˆå«ç§’ï¼‰ï¼Œè¡¨è¾¾å¼: {repo_crontab}")
                                    individual_tasks_created = True
                                elif len(svn_cron_parts) == 5:
                                    # 5æ®µå¼ï¼šåˆ† æ—¶ æ—¥ æœˆ å‘¨ï¼ˆå‘åå…¼å®¹ï¼‰
                                    svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                                    scheduler.add_job(
                                        lambda repo=repo_config: trigger_single_svn_repo_check(repo),
                                        trigger=CronTrigger(
                                            minute=svn_minute,
                                            hour=svn_hour,
                                            day=svn_day,
                                            month=svn_month,
                                            day_of_week=svn_day_of_week
                                        ),
                                        id=f"svn_check_{repo_name}",
                                        name=f"SVNæ£€æŸ¥ä»»åŠ¡ - {repo_name}"
                                    )
                                    logger.info(f"ä¸ºä»“åº“ {repo_name} åˆ›å»ºç‹¬ç«‹å®šæ—¶ä»»åŠ¡ï¼Œè¡¨è¾¾å¼: {repo_crontab}")
                                    individual_tasks_created = True
                                else:
                                    logger.error(f"ä»“åº“ {repo_name} çš„å®šæ—¶è¡¨è¾¾å¼æ ¼å¼é”™è¯¯: {repo_crontab}ï¼Œåº”ä¸º5æ®µæˆ–6æ®µ")
                            else:
                                logger.info(f"ä»“åº“ {repo_name} æœªé…ç½® check_crontabï¼Œå°†ä½¿ç”¨å…¨å±€å®šæ—¶ä»»åŠ¡")
                except (json.JSONDecodeError, Exception) as e:
                    logger.error(f"è§£æ SVN_REPOSITORIES é…ç½®å¤±è´¥: {e}")
            
            # å¦‚æœæ²¡æœ‰ä¸ºä»»ä½•ä»“åº“åˆ›å»ºç‹¬ç«‹ä»»åŠ¡ï¼Œæˆ–è€…æœ‰ä»“åº“æ²¡æœ‰é…ç½® check_crontabï¼Œåˆ™åˆ›å»ºå…¨å±€ä»»åŠ¡
            if not individual_tasks_created or svn_repositories_str:
                svn_crontab = get_env_with_default('SVN_CHECK_CRONTAB')  # é»˜è®¤æ¯30åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                svn_cron_parts = svn_crontab.split()
                
                if len(svn_cron_parts) == 6:
                    # 6æ®µå¼ï¼šç§’ åˆ† æ—¶ æ—¥ æœˆ å‘¨
                    svn_second, svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                    scheduler.add_job(
                        trigger_svn_check,
                        trigger=CronTrigger(
                            second=svn_second,
                            minute=svn_minute,
                            hour=svn_hour,
                            day=svn_day,
                            month=svn_month,
                            day_of_week=svn_day_of_week
                        ),
                        id="svn_check_global",
                        name="SVNå…¨å±€æ£€æŸ¥ä»»åŠ¡"
                    )
                    logger.info(f"SVNå…¨å±€å®šæ—¶æ£€æŸ¥ä»»åŠ¡å·²é…ç½®ï¼ˆå«ç§’ï¼‰ï¼Œå®šæ—¶è¡¨è¾¾å¼: {svn_crontab}")
                elif len(svn_cron_parts) == 5:
                    # 5æ®µå¼ï¼šåˆ† æ—¶ æ—¥ æœˆ å‘¨ï¼ˆå‘åå…¼å®¹ï¼‰
                    svn_minute, svn_hour, svn_day, svn_month, svn_day_of_week = svn_cron_parts
                    scheduler.add_job(
                        trigger_svn_check,
                        trigger=CronTrigger(
                            minute=svn_minute,
                            hour=svn_hour,
                            day=svn_day,
                            month=svn_month,
                            day_of_week=svn_day_of_week
                        ),
                        id="svn_check_global",
                        name="SVNå…¨å±€æ£€æŸ¥ä»»åŠ¡"
                    )
                    logger.info(f"SVNå…¨å±€å®šæ—¶æ£€æŸ¥ä»»åŠ¡å·²é…ç½®ï¼Œå®šæ—¶è¡¨è¾¾å¼: {svn_crontab}")
                else:
                    logger.error(f"SVNå®šæ—¶è¡¨è¾¾å¼æ ¼å¼é”™è¯¯: {svn_crontab}ï¼Œåº”ä¸º5æ®µæˆ–6æ®µ")

        # åœ¨å¯åŠ¨è°ƒåº¦å™¨ä¹‹å‰åˆå§‹åŒ–æ‰€æœ‰SVNä»“åº“
        logger.info("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–SVNä»“åº“...")
        svn_init_success = initialize_all_svn_repositories()
        
        if svn_init_success:
            logger.info("âœ… SVNä»“åº“åˆå§‹åŒ–å®Œæˆï¼Œå¯åŠ¨è°ƒåº¦å™¨...")
        else:
            logger.warning("âš ï¸ SVNä»“åº“åˆå§‹åŒ–å¤±è´¥ï¼Œä½†ä»å°†å¯åŠ¨è°ƒåº¦å™¨ï¼ˆå®šæ—¶ä»»åŠ¡ä¼šå¤„ç†åˆå§‹åŒ–ï¼‰")

        # Start the scheduler
        scheduler.start()
        logger.info("Scheduler started successfully.")        # Shut down the scheduler when exiting the app
        atexit.register(lambda: scheduler.shutdown())
        
    except Exception as e:
        logger.error(f"âŒ Error setting up scheduler: {e}")
        logger.error(f"âŒ Traceback: {traceback.format_exc()}")


# å¤„ç† GitLab Merge Request Webhook
@api_app.route('/review/webhook', methods=['POST'])
def handle_webhook():
    # è·å–è¯·æ±‚çš„JSONæ•°æ®
    if request.is_json:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Invalid JSON"}), 400

        # åˆ¤æ–­æ˜¯GitLabè¿˜æ˜¯GitHubçš„webhook
        webhook_source = request.headers.get('X-GitHub-Event')

        if webhook_source:  # GitHub webhook
            return handle_github_webhook(webhook_source, data)
        else:  # GitLab webhook
            return handle_gitlab_webhook(data)
    else:
        return jsonify({'message': 'Invalid data format'}), 400


def handle_github_webhook(event_type, data):    # è·å–GitHubé…ç½®
    github_token = get_env_with_default('GITHUB_ACCESS_TOKEN') or request.headers.get('X-GitHub-Token')
    if not github_token:
        return jsonify({'message': 'Missing GitHub access token'}), 400

    github_url = get_env_with_default('GITHUB_URL') or 'https://github.com'
    github_url_slug = slugify_url(github_url)

    # æ‰“å°æ•´ä¸ªpayloadæ•°æ®
    logger.info(f'Received GitHub event: {event_type}')
    logger.info(f'Payload: {json.dumps(data)}')

    if event_type == "pull_request":
        # ä½¿ç”¨handle_queueè¿›è¡Œå¼‚æ­¥å¤„ç†
        handle_queue(handle_github_pull_request_event, data, github_token, github_url, github_url_slug)
        # ç«‹é©¬è¿”å›å“åº”
        return jsonify(
            {'message': f'GitHub request received(event_type={event_type}), will process asynchronously.'}), 200
    elif event_type == "push":
        # ä½¿ç”¨handle_queueè¿›è¡Œå¼‚æ­¥å¤„ç†
        handle_queue(handle_github_push_event, data, github_token, github_url, github_url_slug)
        # ç«‹é©¬è¿”å›å“åº”
        return jsonify(
            {'message': f'GitHub request received(event_type={event_type}), will process asynchronously.'}), 200
    else:
        error_message = f'Only pull_request and push events are supported for GitHub webhook, but received: {event_type}.'
        logger.error(error_message)
        return jsonify(error_message), 400


def handle_gitlab_webhook(data):
    object_kind = data.get("object_kind")    # ä¼˜å…ˆä»è¯·æ±‚å¤´è·å–ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™ä»æ¨é€äº‹ä»¶ä¸­è·å–
    gitlab_url = get_env_with_default('GITLAB_URL') or request.headers.get('X-Gitlab-Instance')
    if not gitlab_url:
        repository = data.get('repository')
        if not repository:
            return jsonify({'message': 'Missing GitLab URL'}), 400
        homepage = repository.get("homepage")
        if not homepage:
            return jsonify({'message': 'Missing GitLab URL'}), 400
        try:
            parsed_url = urlparse(homepage)
            gitlab_url = f"{parsed_url.scheme}://{parsed_url.netloc}/"
        except Exception as e:
            return jsonify({"error": f"Failed to parse homepage URL: {str(e)}"}), 400    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™ä»è¯·æ±‚å¤´è·å–
    gitlab_token = get_env_with_default('GITLAB_ACCESS_TOKEN') or request.headers.get('X-Gitlab-Token')
    # å¦‚æœgitlab_tokenä¸ºç©ºï¼Œè¿”å›é”™è¯¯
    if not gitlab_token:
        return jsonify({'message': 'Missing GitLab access token'}), 400

    gitlab_url_slug = slugify_url(gitlab_url)

    # æ‰“å°æ•´ä¸ªpayloadæ•°æ®ï¼Œæˆ–æ ¹æ®éœ€æ±‚è¿›è¡Œå¤„ç†
    logger.info(f'Received event: {object_kind}')
    logger.info(f'Payload: {json.dumps(data)}')

    # å¤„ç†Merge Request Hook
    if object_kind == "merge_request":
        # åˆ›å»ºä¸€ä¸ªæ–°è¿›ç¨‹è¿›è¡Œå¼‚æ­¥å¤„ç†
        handle_queue(handle_merge_request_event, data, gitlab_token, gitlab_url, gitlab_url_slug)
        # ç«‹é©¬è¿”å›å“åº”
        return jsonify(
            {'message': f'Request received(object_kind={object_kind}), will process asynchronously.'}), 200
    elif object_kind == "push":
        # åˆ›å»ºä¸€ä¸ªæ–°è¿›ç¨‹è¿›è¡Œå¼‚æ­¥å¤„ç†
        # TODO check if PUSH_REVIEW_ENABLED is needed here
        handle_queue(handle_push_event, data, gitlab_token, gitlab_url, gitlab_url_slug)
        # ç«‹é©¬è¿”å›å“åº”
        return jsonify(
            {'message': f'Request received(object_kind={object_kind}), will process asynchronously.'}), 200
    else:
        error_message = f'Only merge_request and push events are supported (both Webhook and System Hook), but received: {object_kind}.'
        logger.error(error_message)
        return jsonify(error_message), 400


@api_app.route('/svn/check', methods=['GET', 'POST'])
def manual_svn_check():
    """æ‰‹åŠ¨è§¦å‘SVNæ£€æŸ¥"""
    if not svn_check_enabled:
        return jsonify({'message': 'SVNæ£€æŸ¥åŠŸèƒ½æœªå¯ç”¨'}), 400
    
    try:
        # å…è®¸é€šè¿‡æŸ¥è¯¢å‚æ•°è¦†ç›–æ£€æŸ¥çš„å°æ—¶æ•°
        hours_str = request.args.get('hours')
        if hours_str:
            try:
                hours = int(hours_str)
            except ValueError:
                return jsonify({'message': 'å‚æ•° "hours" å¿…é¡»æ˜¯æ•´æ•°'}), 400
        else:
            hours = None

        # å…è®¸é€šè¿‡æŸ¥è¯¢å‚æ•°æŒ‡å®šä»“åº“åç§°
        repo_name = request.args.get('repo')
        
        # å¼‚æ­¥å¤„ç†SVNæ£€æŸ¥
        if repo_name:
            # æ£€æŸ¥ç‰¹å®šä»“åº“
            handle_queue(trigger_specific_svn_repo, repo_name=repo_name, hours=hours)
            message = f'ä»“åº“ "{repo_name}" çš„SVNæ£€æŸ¥å·²å¯åŠ¨'
        else:
            # æ£€æŸ¥æ‰€æœ‰ä»“åº“
            handle_queue(trigger_svn_check, hours=hours)
            message = 'SVNæ£€æŸ¥å·²å¯åŠ¨'
        
        # å‡†å¤‡å“åº”æ¶ˆæ¯
        if hours is not None:
            message += f'ï¼Œå°†å¼‚æ­¥å¤„ç†æœ€è¿‘ {hours} å°æ—¶çš„æäº¤ã€‚'
        else:
            # ä½¿ç”¨é»˜è®¤çš„24å°æ—¶
            message += f'ï¼Œå°†å¼‚æ­¥å¤„ç†æœ€è¿‘ 24 å°æ—¶çš„æäº¤ã€‚'

        # ä½¿ç”¨è‡ªå®šä¹‰å“åº”ç¡®ä¿ä¸­æ–‡æ­£ç¡®è¾“å‡º
        response_data = {'message': message}
        import json
        json_str = json.dumps(response_data, ensure_ascii=False, indent=2)
        return Response(json_str, content_type='application/json; charset=utf-8'), 200
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨è§¦å‘SVNæ£€æŸ¥å¤±è´¥: {e}")
        error_message = f'æ‰‹åŠ¨è§¦å‘SVNæ£€æŸ¥å¤±è´¥: {str(e)}'
        response_data = {'message': error_message}
        import json
        json_str = json.dumps(response_data, ensure_ascii=False, indent=2)
        return Response(json_str, content_type='application/json; charset=utf-8'), 500


# æ·»åŠ å“åº”åå¤„ç†ï¼Œç¡®ä¿ä¸­æ–‡ç¼–ç æ­£ç¡®
@api_app.after_request  
def after_request(response):
    """è®¾ç½®å“åº”å¤´ä»¥ç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º"""
    if response.content_type.startswith('application/json'):
        response.headers['Content-Type'] = 'application/json; charset=utf-8'
    return response


def acquire_svn_repo_lock(repo_name: str = "global"):
    """ä¸ºç‰¹å®šä»“åº“è·å–äº’æ–¥é”ï¼ŒæˆåŠŸè¿”å›æ–‡ä»¶å¯¹è±¡ï¼Œå¤±è´¥è¿”å›Noneï¼ˆè·¨å¹³å°å®ç°ï¼‰"""
    import os
    import portalocker
    
    # ä¸ºæ¯ä¸ªä»“åº“åˆ›å»ºç‹¬ç«‹çš„é”æ–‡ä»¶
    safe_repo_name = "".join(c for c in repo_name if c.isalnum() or c in ('-', '_')).lower()
    lockfile_path = f"log/svn_check_{safe_repo_name}.lock"
    
    try:
        os.makedirs(os.path.dirname(lockfile_path), exist_ok=True)
        lockfile = open(lockfile_path, "w")
        try:
            portalocker.lock(lockfile, portalocker.LOCK_EX | portalocker.LOCK_NB)
            return lockfile
        except portalocker.exceptions.LockException:
            lockfile.close()
            return None
    except Exception:
        return None

def release_svn_repo_lock(lockfile):
    """é‡Šæ”¾SVNä»“åº“äº’æ–¥é”ï¼ˆè·¨å¹³å°å®ç°ï¼‰"""
    import portalocker
    try:
        portalocker.unlock(lockfile)
        lockfile.close()
    except Exception:
        pass

def trigger_specific_svn_repo(repo_name: str, hours: int = None):
    """è§¦å‘ç‰¹å®šSVNä»“åº“çš„æ£€æŸ¥ï¼ˆå¸¦ä»“åº“çº§äº’æ–¥é”ï¼‰"""
    lock = acquire_svn_repo_lock(repo_name)
    if not lock:
        logger.warning(f"ä»“åº“ {repo_name} å·²æœ‰æ£€æŸ¥ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡æœ¬æ¬¡è§¦å‘ã€‚")
        return
    try:
        if not svn_check_enabled:
            logger.info("SVNæ£€æŸ¥åŠŸèƒ½æœªå¯ç”¨")
            return
        import json
        check_limit = get_env_int('SVN_CHECK_LIMIT')
        svn_repositories_config = get_env_with_default('SVN_REPOSITORIES')
        try:
            repositories = json.loads(svn_repositories_config)
        except json.JSONDecodeError as e:
            logger.error(f"SVNä»“åº“é…ç½®JSONè§£æå¤±è´¥: {e}")
            return
        target_repo = None
        for repo_config in repositories:
            if repo_config.get('name') == repo_name:
                target_repo = repo_config
                break
        if not target_repo:
            logger.error(f"æœªæ‰¾åˆ°åä¸º '{repo_name}' çš„ä»“åº“é…ç½®")
            return
        remote_url = target_repo.get('remote_url')
        local_path = target_repo.get('local_path')
        username = target_repo.get('username')
        password = target_repo.get('password')
        repo_check_hours = hours or target_repo.get('check_hours', 24)
        if not remote_url or not local_path:
            logger.error(f"ä»“åº“ {repo_name} é…ç½®ä¸å®Œæ•´")
            return
        logger.info(f"å¼€å§‹æ£€æŸ¥æŒ‡å®šä»“åº“: {repo_name}")
        handle_svn_changes(remote_url, local_path, username, password, repo_check_hours, check_limit, repo_name, "manual", target_repo)
    finally:
        release_svn_repo_lock(lock)


def trigger_svn_check(hours: int = None):
    """è§¦å‘SVNæ£€æŸ¥ï¼ˆå…¨å±€æ¨¡å¼ä½¿ç”¨å…¨å±€é”ï¼‰"""
    lock = acquire_svn_repo_lock("global")
    if not lock:
        logger.warning("å·²æœ‰å…¨å±€SVNæ£€æŸ¥ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡æœ¬æ¬¡è§¦å‘ã€‚")
        return
    try:
        if not svn_check_enabled:
            logger.info("SVNæ£€æŸ¥åŠŸèƒ½æœªå¯ç”¨")
            return
        check_limit = get_env_int('SVN_CHECK_LIMIT')    
        svn_repositories_config = get_env_with_default('SVN_REPOSITORIES')
        if svn_repositories_config and svn_repositories_config.strip() != '[]':
            logger.info("ä½¿ç”¨å¤šä»“åº“é…ç½®è¿›è¡ŒSVNæ£€æŸ¥")
            logger.debug(f"SVN_REPOSITORIES é…ç½®é•¿åº¦: {len(svn_repositories_config)}")
            logger.debug(f"å‰50å­—ç¬¦: {repr(svn_repositories_config[:50])}")
            logger.debug(f"å10å­—ç¬¦: {repr(svn_repositories_config[-10:])}")
            if "'" in svn_repositories_config and '"' not in svn_repositories_config:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°é…ç½®ä¸­ä½¿ç”¨äº†å•å¼•å·ï¼ŒJSONè¦æ±‚ä½¿ç”¨åŒå¼•å·")
            handle_multiple_svn_repositories(svn_repositories_config, hours, check_limit, "scheduled")
            return
        svn_remote_url = get_env_with_default('SVN_REMOTE_URL')
        svn_local_path = get_env_with_default('SVN_LOCAL_PATH')
        if not svn_remote_url or not svn_local_path:
            logger.error("SVN_REPOSITORIES æˆ– SVN_REMOTE_URL+SVN_LOCAL_PATH ç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®")
            return
        svn_username = get_env_with_default('SVN_USERNAME')
        svn_password = get_env_with_default('SVN_PASSWORD')
        if hours is None:
            check_hours = get_env_int('SVN_CHECK_INTERVAL_HOURS')
        else:
            check_hours = hours
        logger.info(f"ä½¿ç”¨å•ä»“åº“é…ç½®è¿›è¡ŒSVNæ£€æŸ¥ï¼Œè¿œç¨‹URL: {svn_remote_url}, æœ¬åœ°è·¯å¾„: {svn_local_path}, æ£€æŸ¥æœ€è¿‘ {check_hours} å°æ—¶")
        handle_svn_changes(svn_remote_url, svn_local_path, svn_username, svn_password, check_hours, check_limit, None, "scheduled", None)
    finally:
        release_svn_repo_lock(lock)


def trigger_single_svn_repo_check(repo_config: dict):
    """è§¦å‘å•ä¸ªSVNä»“åº“æ£€æŸ¥ï¼ˆå¸¦ä»“åº“çº§äº’æ–¥é”ï¼‰"""
    repo_name = repo_config.get('name', 'unknown')
    lock = acquire_svn_repo_lock(repo_name)
    if not lock:
        logger.warning(f"ä»“åº“ {repo_name} å·²æœ‰æ£€æŸ¥ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡æœ¬æ¬¡æ£€æŸ¥ã€‚")
        return
    try:
        if not svn_check_enabled:
            logger.info("SVNæ£€æŸ¥åŠŸèƒ½æœªå¯ç”¨")
            return
        
        repo_name = repo_config.get('name', 'unknown')
        remote_url = repo_config.get('remote_url')
        local_path = repo_config.get('local_path')
        username = repo_config.get('username')
        password = repo_config.get('password')
        check_hours = repo_config.get('check_hours', 24)
        check_limit = repo_config.get('check_limit', get_env_int('SVN_CHECK_LIMIT'))
        
        if not remote_url or not local_path:
            logger.error(f"ä»“åº“ {repo_name} é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡æ£€æŸ¥")
            return
        
        logger.info(f"å¼€å§‹ç‹¬ç«‹æ£€æŸ¥ä»“åº“: {repo_name}")
        handle_svn_changes(remote_url, local_path, username, password, check_hours, check_limit, repo_name, "scheduled", repo_config)
        
    except Exception as e:
        error_message = f'å•ç‹¬è§¦å‘ä»“åº“ {repo_config.get("name", "unknown")} æ£€æŸ¥æ—¶å‡ºç°é”™è¯¯: {str(e)}\n{traceback.format_exc()}'
        logger.error(error_message)
        from biz.utils.reporter import notifier
        notifier.send_notification(content=error_message)
    finally:
        release_svn_repo_lock(lock)


# æ·»åŠ é…ç½®é‡è½½çš„APIç«¯ç‚¹
@api_app.route('/reload-config', methods=['POST'])
def reload_config_endpoint():
    """é…ç½®é‡è½½APIç«¯ç‚¹"""
    try:
        reload_config()
        return jsonify({
            "success": True,
            "message": "é…ç½®å·²æˆåŠŸé‡æ–°åŠ è½½",
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"é…ç½®é‡è½½å¤±è´¥: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }), 500


def start_background_tasks():
    """å¯åŠ¨åå°ä»»åŠ¡ï¼ˆå•æœåŠ¡æ¶æ„ï¼‰"""
    global background_threads
    
    logger.info("ğŸš€ åˆå§‹åŒ–åå°ä»»åŠ¡...")
    
    # å¯åŠ¨ SVN åå°ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    svn_enabled = get_env_bool('SVN_CHECK_ENABLED')
    if svn_enabled:
        try:
            from biz.svn.svn_worker import main as svn_main
            
            def svn_worker_thread():
                """SVNå·¥ä½œçº¿ç¨‹"""
                try:
                    logger.info("ğŸš€ å¯åŠ¨ SVN åå°ä»»åŠ¡å¤„ç†å™¨")
                    # åªæ‰§è¡Œä¸€æ¬¡ï¼Œç”±è°ƒåº¦å™¨æ§åˆ¶é¢‘ç‡
                    svn_main()
                except Exception as e:
                    logger.error(f"âŒ SVN ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¯åŠ¨SVNä»»åŠ¡
            thread = threading.Thread(target=svn_worker_thread, daemon=True)
            thread.start()
            background_threads.append(thread)
            logger.info("âœ… SVN åå°ä»»åŠ¡å·²å¯åŠ¨")
            
        except ImportError as e:
            logger.error(f"âŒ SVN åå°ä»»åŠ¡å¯åŠ¨å¤±è´¥ (ç¼ºå°‘ä¾èµ–): {e}")
        except Exception as e:
            logger.error(f"âŒ SVN åå°ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
    else:
        logger.info("â„¹ï¸ SVN æ£€æŸ¥å·²ç¦ç”¨")
    
    logger.info("âœ… åå°ä»»åŠ¡åˆå§‹åŒ–å®Œæˆ")

def shutdown_background_tasks():
    """å…³é—­åå°ä»»åŠ¡"""
    global background_threads, scheduler
    
    logger.info("â¹ï¸ æ­£åœ¨å…³é—­åå°ä»»åŠ¡...")
    
    # å…³é—­è°ƒåº¦å™¨
    if scheduler:
        scheduler.shutdown()
    
    # ç­‰å¾…åå°çº¿ç¨‹ç»“æŸ
    for thread in background_threads:
        if thread.is_alive():
            logger.info(f"ç­‰å¾…çº¿ç¨‹ {thread.name} ç»“æŸ...")
            thread.join(timeout=5)
    
    logger.info("âœ… åå°ä»»åŠ¡å·²å…³é—­")
    
@api_app.route('/review/retry', methods=['POST'])
def retry_review():
    """
    ç®¡ç†å‘˜è§¦å‘çš„é‡æ–°AIè¯„å®¡æ¥å£
    ä¼ å…¥å‚æ•°ï¼štypeï¼ˆmr/push/svn/githubï¼‰ã€å”¯ä¸€æ ‡è¯†ï¼ˆå¦‚id/commit_sha/version_hashï¼‰
    """
    data = request.get_json()
    review_type = data.get('type')
    identifier = data.get('id') or data.get('commit_sha') or data.get('version_hash')
    if not review_type or not identifier:
        return jsonify({"success": False, "message": "ç¼ºå°‘typeæˆ–å”¯ä¸€æ ‡è¯†å‚æ•°"}), 400
    try:
        from biz.service.review_service import ReviewService
        result = ReviewService.retry_review(review_type, identifier)
        return jsonify(result)
    except Exception as e:
        logger.error(f"é‡æ–°è¯„å®¡å¤±è´¥: {e}")
        return jsonify({"success": False, "message": f"é‡æ–°è¯„å®¡å¤±è´¥: {e}"}), 500


def initialize_all_svn_repositories():
    """åœ¨å¯åŠ¨å®šæ—¶å™¨å‰åˆå§‹åŒ–æ‰€æœ‰SVNä»“åº“"""
    try:
        if not svn_check_enabled:
            logger.info("SVNæ£€æŸ¥åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡SVNä»“åº“åˆå§‹åŒ–")
            return True
        
        logger.info("å¼€å§‹åˆå§‹åŒ–SVNä»“åº“...")
        
        # è·å–SVNä»“åº“é…ç½®
        svn_repositories_config = get_env_with_default('SVN_REPOSITORIES')
        
        if svn_repositories_config and svn_repositories_config.strip() != '[]':
            # å¤šä»“åº“æ¨¡å¼
            import json
            try:
                repositories = json.loads(svn_repositories_config)
                if isinstance(repositories, list):
                    logger.info(f"å‘ç° {len(repositories)} ä¸ªSVNä»“åº“é…ç½®ï¼Œå¼€å§‹åˆå§‹åŒ–...")
                    
                    for repo_config in repositories:
                        repo_name = repo_config.get('name', 'unknown')
                        remote_url = repo_config.get('remote_url')
                        local_path = repo_config.get('local_path')
                        username = repo_config.get('username')
                        password = repo_config.get('password')
                        
                        if not remote_url or not local_path:
                            logger.warning(f"ä»“åº“ {repo_name} é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡åˆå§‹åŒ–")
                            continue
                        
                        try:
                            logger.info(f"åˆå§‹åŒ–ä»“åº“: {repo_name}")
                            from biz.svn.svn_handler import SVNHandler
                            
                            # åˆ›å»ºSVNå¤„ç†å™¨å¹¶åˆå§‹åŒ–å·¥ä½œå‰¯æœ¬
                            svn_handler = SVNHandler(remote_url, local_path, username, password)
                            svn_handler._prepare_working_copy()
                            
                            logger.info(f"âœ… ä»“åº“ {repo_name} åˆå§‹åŒ–å®Œæˆ")
                            
                        except Exception as e:
                            logger.error(f"âŒ ä»“åº“ {repo_name} åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                            # ç»§ç»­åˆå§‹åŒ–å…¶ä»–ä»“åº“ï¼Œä¸å› å•ä¸ªä»“åº“å¤±è´¥è€Œåœæ­¢
                            continue
                    
                    logger.info("âœ… å¤šä»“åº“SVNåˆå§‹åŒ–å®Œæˆ")
                    return True
                    
                else:
                    logger.error("SVN_REPOSITORIES é…ç½®æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»æ˜¯æ•°ç»„")
                    return False
                    
            except json.JSONDecodeError as e:
                logger.error(f"è§£æ SVN_REPOSITORIES é…ç½®å¤±è´¥: {e}")
                return False
        else:
            # å•ä»“åº“æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            svn_remote_url = get_env_with_default('SVN_REMOTE_URL')
            svn_local_path = get_env_with_default('SVN_LOCAL_PATH')
            svn_username = get_env_with_default('SVN_USERNAME')
            svn_password = get_env_with_default('SVN_PASSWORD')
            
            if svn_remote_url and svn_local_path:
                try:
                    logger.info("åˆå§‹åŒ–å•SVNä»“åº“...")
                    from biz.svn.svn_handler import SVNHandler
                    
                    svn_handler = SVNHandler(svn_remote_url, svn_local_path, svn_username, svn_password)
                    svn_handler._prepare_working_copy()
                    
                    logger.info("âœ… å•SVNä»“åº“åˆå§‹åŒ–å®Œæˆ")
                    return True
                    
                except Exception as e:
                    logger.error(f"âŒ å•SVNä»“åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    return False
            else:
                logger.info("æœªé…ç½®SVNä»“åº“ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return True
                
    except Exception as e:
        logger.error(f"âŒ SVNä»“åº“åˆå§‹åŒ–è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
        logger.error(f"âŒ Traceback: {traceback.format_exc()}")
        return False


if __name__ == '__main__':
    try:
        logger.info("ğŸš€ å¯åŠ¨ AI-CodeReview ç»Ÿä¸€æœåŠ¡")
        
        check_config()
        
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
        setup_scheduler()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        start_background_tasks()
        
        # åˆå§‹åŒ–SVNä»“åº“
        initialize_all_svn_repositories()
        
        # å¯åŠ¨Flask APIæœåŠ¡
        port = get_env_int('API_PORT')
        logger.info("=" * 60)
        logger.info("ğŸš€ AI-CodeReview API æœåŠ¡å¯åŠ¨ä¸­...")
        logger.info(f"ğŸŒ æœåŠ¡åœ°å€: http://0.0.0.0:{port}")
        logger.info(f"ğŸ“Š æ—¥å¿—çº§åˆ«: {logger.level}")
        logger.info(f"ğŸ”§ é…ç½®æ£€æŸ¥: {'âœ… é€šè¿‡' if check_config() else 'âŒ å¤±è´¥'}")
        logger.info(f"â° å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 60)
        
        # æ³¨å†Œä¼˜é›…å…³é—­å¤„ç†
        atexit.register(shutdown_background_tasks)
        
        # å¯åŠ¨ Flask åº”ç”¨ï¼Œåœ¨ Docker ç¯å¢ƒä¸‹ä½¿ç”¨è°ƒè¯•æ¨¡å¼ä¾¿äºæŸ¥çœ‹æ—¥å¿—
        debug_mode = os.getenv('DOCKER_ENV') == 'true'
        api_app.run(host='0.0.0.0', port=port, debug=debug_mode, use_reloader=False)
    except KeyboardInterrupt:
        logger.info("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
        shutdown_background_tasks()
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        shutdown_background_tasks()
        raise


